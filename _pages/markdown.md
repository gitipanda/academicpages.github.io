---
layout: archive
title: 
permalink: /markdown/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}



<span style="font-size:18pt;">**Publication**</span>
* Fast Global Convergence in Random Sensing Problems for Low-rank Matrix with Random Initialization. Thomas Y. Hou, Zhenzhen Li, Ziyun Zhang, 2021.

* Robust low-rank matrix recovery by Riemannian subgradient method (working paper). Thomas Y. Hou, Zhenzhen Li, Ziyun Zhang, 2021.

* [Asymptotic escape of spurious fixed points on the low-rank matrix manifold](https://arxiv.org/abs/2107.09207). Thomas Y. Hou, Zhenzhen Li, Ziyun Zhang, submitted to Communications of the AMS, 2021.

* [Fast Global Convergence for Low-rank Matrix Recovery via Riemannian Gradient Descent with Random Initialization](https://arxiv.org/abs/2012.15467). Thomas Y. Hou, Zhenzhen Li, Ziyun Zhang, submitted to Foundations of Computational Mathematics (FoCM), 2021.

* [Analysis of Asymptotic Escape of Strict Saddle Sets in Manifold Optimization](https://epubs.siam.org/doi/abs/10.1137/19M129437X?mobileUi=0&). Thomas Y. Hou, Zhenzhen Li, Ziyun Zhang, SIAM Journal on Mathematics of Data Science, 2020, 2(3): 840-871.

* [Nonconvex Optimization for Low-rank Matrix Related Problems]. Zhenzhen Li, Ph.D. Thesis, Hong Kong University of Science and Technology, 2020.

*  [Towards the Optimal Construction of a Loss Function without Spurious Local Minima for Solving Quadratic Equations](https://ieeexplore.ieee.org/document/8918236). Zhenzhen Li, Jian-feng Cai, Ke Wei, IEEE Transactions on Information Theory, 66(5): 3242--3260, 2020.
